# core/agent/pentest_orchestrator.py
# DRAKBEN Pentest Orchestrator - State Machine & LLM Coordinator
# Author: @drak_ben
"""
This module implements a hybrid approach:
- CODE controls the flow (state machine)
- LLM provides intelligence (analysis, suggestions)
- Tool execution is deterministic
- Output analysis uses LLM

State Flow:
    IDLE → TARGET_SET → RECON → VULN_SCAN → EXPLOIT → POST_EXPLOIT → COMPLETE
"""

import logging
import platform
import subprocess
import threading
import time
from dataclasses import dataclass, field
from enum import Enum, auto
from typing import Any

logger = logging.getLogger(__name__)


class PentestPhase(Enum):
    """Pentest phases - deterministic state machine."""
    IDLE = auto()           # No target, chat mode
    TARGET_SET = auto()     # Target configured, ready to start
    RECON = auto()          # Reconnaissance phase
    VULN_SCAN = auto()      # Vulnerability scanning
    EXPLOIT = auto()        # Exploitation attempts
    POST_EXPLOIT = auto()   # Post-exploitation
    REPORTING = auto()      # Generating report
    COMPLETE = auto()       # Mission complete


@dataclass
class PentestContext:
    """Current pentest context - passed to LLM for analysis."""
    target: str | None = None
    phase: PentestPhase = PentestPhase.IDLE
    language: str = "tr"

    # Findings
    open_ports: list[dict] = field(default_factory=list)
    services: list[dict] = field(default_factory=list)
    vulnerabilities: list[dict] = field(default_factory=list)
    credentials: list[dict] = field(default_factory=list)

    # History
    executed_tools: list[str] = field(default_factory=list)
    tool_outputs: list[dict] = field(default_factory=list)
    llm_analyses: list[dict] = field(default_factory=list)

    # System info
    is_kali: bool = False
    os_name: str = ""
    available_tools: list[str] = field(default_factory=list)


# Compact LLM Prompts (focused, 15 lines max)
PROMPTS = {
    "analyze_output": """You are DRAKBEN, elite pentester. Analyze this tool output.
Target: {target} | Phase: {phase}

TOOL OUTPUT:
{output}

Respond in {lang}. JSON only:
{{"findings": ["finding1", "finding2"], "next_action": "suggested_tool or null", "severity": "info|low|medium|high|critical", "summary": "2-3 sentence analysis"}}""",

    "chat": """You are DRAKBEN, professional security expert.
Current target: {target} | Phase: {phase}
System: {os_name} (Kali: {is_kali})

Rules:
- Be professional, concise, technical
- No emojis
- Answer in {lang}
- If no target set and user asks to scan, tell them to set target first

User: {user_input}""",

    "suggest_next": """You are DRAKBEN pentester. Based on current findings, suggest next action.
Target: {target} | Phase: {phase}
Open ports: {ports}
Services: {services}
Vulnerabilities: {vulns}

Suggest ONE next action. JSON only:
{{"tool": "nmap|nikto|gobuster|sqlmap|hydra|manual", "command": "full command", "reason": "why this tool"}}""",
}


class PentestOrchestrator:
    """Main orchestrator - controls flow, delegates analysis to LLM."""

    def __init__(self, llm_client: Any = None) -> None:
        self.llm_client = llm_client
        self.context = PentestContext()
        self._tool_cache: dict[str, bool] = {}  # Cache for tool availability
        self._init_system_info()

        # Tool Registry integration
        from core.tools.tool_registry import get_registry
        self.tools = get_registry()

    def _init_system_info(self) -> None:
        """Detect system environment."""
        self.context.os_name = platform.system()
        self.context.is_kali = self._detect_kali()
        self.context.available_tools = self._detect_tools()

    def _detect_kali(self) -> bool:
        """Check if running on Kali Linux (or Kali in WSL)."""
        import platform

        system = platform.system()

        if system == "Linux":
            try:
                with open("/etc/os-release") as f:
                    return "kali" in f.read().lower()
            except OSError:
                return False

        if system == "Windows":
            # Check for Kali in WSL
            import subprocess
            try:
                result = subprocess.run(
                    ["wsl", "cat", "/etc/os-release"],
                    capture_output=True, text=True, timeout=3, check=False,
                )
                if result.returncode == 0 and "kali" in result.stdout.lower():
                    return True
            except (OSError, subprocess.SubprocessError):
                pass

        return False

    def _is_tool_available(self, tool: str) -> bool:
        """Check if tool is available (with caching)."""
        if tool in self._tool_cache:
            return self._tool_cache[tool]

        try:
            cmd = ["which", tool] if platform.system() != "Windows" else ["where", tool]
            result = subprocess.run(cmd, capture_output=True, timeout=2)
            available = result.returncode == 0
        except (OSError, subprocess.SubprocessError):
            available = False

        self._tool_cache[tool] = available
        return available

    def _detect_tools(self) -> list[str]:
        """Detect available pentest tools."""
        common_tools = ["nmap", "nikto", "gobuster", "sqlmap", "hydra", "metasploit"]
        return [tool for tool in common_tools if self._is_tool_available(tool)]

    # =========================================================================
    # STATE MANAGEMENT
    # =========================================================================

    def set_target(self, target: str) -> dict:
        """Set target and transition to TARGET_SET phase."""
        self.context.target = target
        self.context.phase = PentestPhase.TARGET_SET

        lang = self.context.language
        msg = f"Hedef ayarlandı: {target}" if lang == "tr" else f"Target set: {target}"

        return {
            "success": True,
            "message": msg,
            "phase": self.context.phase.name,
            "suggested_actions": self._get_phase_actions(),
        }

    def clear_target(self) -> dict:
        """Clear target and reset to IDLE."""
        self.context = PentestContext(
            language=self.context.language,
            is_kali=self.context.is_kali,
            os_name=self.context.os_name,
            available_tools=self.context.available_tools,
        )

        lang = self.context.language
        msg = "Hedef temizlendi." if lang == "tr" else "Target cleared."

        return {"success": True, "message": msg, "phase": "IDLE"}

    def advance_phase(self) -> PentestPhase:
        """Advance to next logical phase."""
        transitions = {
            PentestPhase.IDLE: PentestPhase.IDLE,  # Need target
            PentestPhase.TARGET_SET: PentestPhase.RECON,
            PentestPhase.RECON: PentestPhase.VULN_SCAN,
            PentestPhase.VULN_SCAN: PentestPhase.EXPLOIT,
            PentestPhase.EXPLOIT: PentestPhase.POST_EXPLOIT,
            PentestPhase.POST_EXPLOIT: PentestPhase.REPORTING,
            PentestPhase.REPORTING: PentestPhase.COMPLETE,
        }

        self.context.phase = transitions.get(self.context.phase, self.context.phase)
        return self.context.phase

    def _get_phase_actions(self) -> list[dict]:
        """Get suggested actions for current phase from ToolRegistry."""
        target = self.context.target or "<target>"

        # Map orchestrator phase to registry phase
        from core.tools.tool_registry import PentestPhase as RegistryPhase

        phase_map = {
            PentestPhase.TARGET_SET: RegistryPhase.RECON,
            PentestPhase.RECON: RegistryPhase.RECON,
            PentestPhase.VULN_SCAN: RegistryPhase.VULN_SCAN,
            PentestPhase.EXPLOIT: RegistryPhase.EXPLOIT,
            PentestPhase.POST_EXPLOIT: RegistryPhase.POST_EXPLOIT,
        }

        registry_phase = phase_map.get(self.context.phase)
        if not registry_phase:
            return []

        # Get tools for this phase
        tools = self.tools.list_tools(phase=registry_phase)

        actions = []
        for tool in tools[:3]:  # Limit to 3 suggestions
            if tool.command_template:
                cmd = tool.command_template.format(target=target)
            else:
                cmd = tool.name  # Python tool - just name

            actions.append({
                "tool": tool.name,
                "command": cmd,
                "description": tool.description,
            })

        return actions

    def list_available_tools(self) -> list[str]:
        """List all available tools from registry."""
        return self.tools.list_names()

    # =========================================================================
    # TOOL EXECUTION
    # =========================================================================

    def execute_tool(self, command: str, timeout: int = 300, live_output: bool = True, analyze: bool = True) -> dict:
        """Execute a tool with optional live output and LLM analysis.

        Args:
            command: Shell command OR registered tool name (e.g., "nmap", "passive_recon")
            timeout: Max execution time in seconds
            live_output: If True, show output in real-time
            analyze: If True, send output to LLM for analysis
        """
        # Check if this is a registered tool name (not a full command)
        tool_name = command.split()[0] if command else "unknown"
        registered_tool = self.tools.get(tool_name)

        # If it's a registered tool and no target in command, use context target
        if registered_tool and self.context.target and tool_name == command.strip():
            # Execute via registry
            result = self.tools.execute(tool_name, self.context.target, live_output=live_output)
        else:
            # Execute as raw shell command
            result = self._execute_raw_command(command, timeout, live_output)

        # Store in context
        self.context.executed_tools.append(tool_name)
        self.context.tool_outputs.append({
            "tool": tool_name,
            "command": command,
            "output": result.get("output", "")[:10000],
            "success": result.get("success", False),
            "timestamp": time.time(),
        })

        # LLM Analysis if enabled and output exists
        if analyze and result.get("success") and result.get("output"):
            analysis = self.analyze_output(result["output"])
            result["analysis"] = analysis.get("analysis", {})

            # Print analysis summary
            if analysis.get("success"):
                summary = analysis.get("analysis", {}).get("summary", "")
                if summary:
                    print(f"\n[Analysis] {summary}")

        return result

    @staticmethod
    def _validate_command(command: str) -> str | None:
        """Validate command against injection patterns. Returns error or None."""
        # C-2 FIX: Basic command injection guard for LLM-derived commands
        _INJECTION_PATTERNS = (
            "$(", "`",  # command substitution
            "; rm ", "; curl ", "; wget ",  # chained destructive
            ">/etc/", ">> /etc/",  # system file overwrites
            "| bash", "| sh", "| python",  # pipe to interpreter
        )
        cmd_lower = command.lower().strip()
        for pattern in _INJECTION_PATTERNS:
            if pattern.lower() in cmd_lower:
                return f"Blocked suspicious pattern: {pattern!r}"
        return None

    def _execute_raw_command(self, command: str, timeout: int, live_output: bool) -> dict:
        """Execute a raw shell command."""
        tool_name = command.split()[0] if command else "unknown"

        # C-2 FIX: Validate command before shell execution
        validation_error = self._validate_command(command)
        if validation_error:
            logger.warning("Command blocked: %s — %s", command, validation_error)
            return {"success": False, "error": validation_error, "tool": tool_name}

        logger.info("Executing: %s", command)

        try:
            if live_output:
                # Live output mode - user sees it in real-time
                process = subprocess.Popen(
                    command,
                    shell=True,  # nosec B602 - Pentest tool requires shell for pipes/redirects
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1,
                )

                output_lines = []
                try:
                    for line in process.stdout:
                        print(line, end="", flush=True)  # Live print
                        output_lines.append(line)
                    process.wait(timeout=timeout)
                except subprocess.TimeoutExpired:
                    process.kill()
                    return {"success": False, "error": "Timeout", "tool": tool_name}

                output = "".join(output_lines)
                success = process.returncode == 0
                returncode = process.returncode
            else:
                # Silent mode - capture all then return
                result = subprocess.run(
                    command,
                    shell=True,  # nosec B602 - Pentest tool requires shell for pipes/redirects
                    capture_output=True,
                    text=True,
                    timeout=timeout,
                )
                output = result.stdout + result.stderr
                success = result.returncode == 0
                returncode = result.returncode

            return {
                "success": success,
                "output": output,
                "tool": tool_name,
                "returncode": returncode,
            }

        except subprocess.TimeoutExpired:
            return {"success": False, "error": "Timeout", "tool": tool_name}
        except Exception as e:
            return {"success": False, "error": str(e), "tool": tool_name}

    # =========================================================================
    # LLM INTEGRATION
    # =========================================================================

    def analyze_output(self, tool_output: str) -> dict:
        """Use LLM to analyze tool output."""
        if not self.llm_client:
            return self._offline_analysis(tool_output)

        prompt = PROMPTS["analyze_output"].format(
            target=self.context.target or "N/A",
            phase=self.context.phase.name,
            output=tool_output[:8000],
            lang="Turkish" if self.context.language == "tr" else "English",
        )

        try:
            response = self.llm_client.query(prompt, timeout=30)

            # Try to parse JSON
            import json
            try:
                analysis = json.loads(response)
            except json.JSONDecodeError:
                analysis = {"summary": response, "findings": [], "next_action": None}

            # Store analysis
            self.context.llm_analyses.append(analysis)

            # Extract findings
            self._process_findings(analysis.get("findings", []))

            return {"success": True, "analysis": analysis}

        except Exception as e:
            logger.warning("LLM analysis failed: %s", e)
            return self._offline_analysis(tool_output)

    def _offline_analysis(self, output: str) -> dict:
        """Basic offline analysis without LLM."""
        import re as _re

        findings: list[str] = []
        out_lower = output.lower()
        severity = "info"

        # --- Port / Service detection (nmap-style) ---
        if _re.search(r'\d{1,5}/tcp\s+open', out_lower):
            findings.append("Open ports detected (nmap-style)")
        elif "state: open" in out_lower:
            findings.append("Open ports detected")

        # --- Web servers ---
        web_servers = ["apache", "nginx", "iis", "lighttpd", "caddy", "tomcat"]
        detected = [s for s in web_servers if s in out_lower]
        if detected:
            findings.append(f"Web server detected: {', '.join(detected)}")

        # --- Common services ---
        service_map = {
            "ssh": "SSH", "ftp": "FTP", "smtp": "SMTP", "dns": "DNS",
            "rdp": "RDP", "mysql": "MySQL", "mssql": "MSSQL",
            "postgresql": "PostgreSQL", "redis": "Redis", "mongodb": "MongoDB",
            "smb": "SMB", "snmp": "SNMP", "ldap": "LDAP", "telnet": "Telnet",
        }
        for keyword, label in service_map.items():
            if _re.search(rf'\b{keyword}\b', out_lower):
                findings.append(f"{label} service detected")

        # --- Vulnerability indicators ---
        if _re.search(r'CVE-\d{4}-\d{4,}', output, _re.IGNORECASE):
            findings.append("CVE reference found")
            severity = "high"
        if _re.search(r'\b(vulnerable|vuln|exploitable)\b', out_lower):
            findings.append("Potential vulnerability mentioned")
            severity = "high" if severity != "critical" else severity

        # --- Credentials / Secrets ---
        if _re.search(r'\b(password|passwd|credential|secret|token)\s*[:=]', out_lower):
            findings.append("Possible credential/secret exposure")
            severity = "critical"

        # --- HTTP status codes ---
        if _re.search(r'\bHTTP[/ ]\d\.\d\s+(4\d{2}|5\d{2})\b', output):
            findings.append("HTTP error status codes detected")
        if _re.search(r'\b(403 forbidden|401 unauthorized)\b', out_lower):
            findings.append("Authentication/authorization barrier detected")

        # --- SSL/TLS issues ---
        if _re.search(r'\b(ssl error|certificate expired|self.signed|weak cipher)\b', out_lower):
            findings.append("SSL/TLS issue detected")

        # --- Errors (specific, not overly broad) ---
        if _re.search(r'\b(traceback|exception|segfault|core dump|stack trace)\b', out_lower):
            findings.append("Application error/crash detected")

        # --- Directory listing ---
        if _re.search(r'\b(index of /|directory listing|parent directory)\b', out_lower):
            findings.append("Directory listing enabled")

        return {
            "success": True,
            "analysis": {
                "summary": "Offline analysis - pattern matching",
                "findings": findings,
                "next_action": None,
                "severity": severity,
            },
        }

    def _process_findings(self, findings: list) -> None:
        """Process and store findings from analysis."""
        import re

        for finding in findings:
            if isinstance(finding, str):
                lower = finding.lower()
                # Try to extract port info from strings like "port 80 open", "22/tcp open"
                if "port" in lower and "open" in lower:
                    port_match = re.search(r'(\d{1,5})\s*/?\s*(?:tcp|udp)?\s*open', lower)
                    if not port_match:
                        port_match = re.search(r'port\s+(\d{1,5})\s+.*open', lower)
                    if port_match:
                        port_num = int(port_match.group(1))
                        if 1 <= port_num <= 65535:
                            self.context.open_ports.append({
                                "port": port_num,
                                "description": finding,
                            })
                    else:
                        # Could not extract port number, still store as generic finding
                        self.context.open_ports.append({"description": finding})
                elif "vuln" in lower:
                    self.context.vulnerabilities.append({"description": finding})

    def chat(self, user_input: str) -> dict:
        """Handle chat/question from user.

        Pipeline:
        1. Extract target from natural language if possible.
        2. If input looks like a registered tool name → run it directly.
        3. If input looks like an action keyword → suggest next step.
        4. Otherwise → LLM chat (or offline fallback).
        """
        # 1. Try to extract target from text
        extracted_target = self._extract_target_from_text(user_input)
        if extracted_target and not self.context.target:
            self.set_target(extracted_target)

        # 2. Direct tool dispatch — "nmap", "nikto", "gobuster" etc.
        first_word = user_input.strip().split()[0].lower() if user_input.strip() else ""
        registered = self.tools.get(first_word)
        if registered:
            if not self.context.target:
                return self._no_target_response()
            result = self.execute_tool(user_input.strip(), analyze=bool(self.llm_client))
            output = result.get("output", "")
            if result.get("success"):
                summary = output[:2000] if output else "Tamamlandı."
                return {"success": True, "response": summary, "intent": "tool_exec", "tool": first_word}
            return {"success": False, "response": result.get("error", "Araç çalıştırılamadı."), "intent": "tool_exec"}

        # 3. Action keywords → suggest next step
        is_action = self._is_action_request(user_input)
        if is_action and not self.context.target:
            return self._no_target_response()
        if is_action and self.context.target:
            return self._action_response()

        # 4. LLM chat or offline fallback
        return self._llm_chat(user_input)

    def _is_action_request(self, text: str) -> bool:
        """Check if text contains action keywords."""
        action_words = [
            "tara", "scan", "exploit", "saldır", "attack", "keşfet",
            "recon", "analiz", "enumerate", "brute", "fuzz", "crack",
        ]
        return any(w in text.lower() for w in action_words)

    def _no_target_response(self) -> dict:
        """Return response when no target is set."""
        lang = self.context.language
        if lang == "tr":
            msg = "Hedef belirtmediniz. Ornek: 'example.com sitesini tara' veya /target example.com"
        else:
            msg = "No target specified. Example: 'scan example.com' or /target example.com"
        return {"success": True, "response": msg, "intent": "needs_target"}

    def _action_response(self) -> dict:
        """Return action response with suggestion."""
        lang = self.context.language
        suggestion = self._get_phase_actions()
        if suggestion:
            action = suggestion[0]
            if lang == "tr":
                msg = f"Hedef: {self.context.target}\nOnerilen: {action.get('tool', '?')} - {action.get('description', '')}"
            else:
                msg = f"Target: {self.context.target}\nSuggested: {action.get('tool', '?')} - {action.get('description', '')}"
            return {"success": True, "response": msg, "intent": "action", "suggestion": action}
        return {"success": True, "response": "No suggestions", "intent": "chat"}

    def _llm_chat(self, user_input: str) -> dict:
        """Process chat with LLM or offline fallback."""
        if self.llm_client:
            # Check if client actually has a valid API key
            if not getattr(self.llm_client, "api_key", None):
                return self._offline_chat(user_input)

            prompt = PROMPTS["chat"].format(
                target=self.context.target or "None",
                phase=self.context.phase.name,
                os_name=self.context.os_name,
                is_kali="Yes" if self.context.is_kali else "No",
                lang="Turkish" if self.context.language == "tr" else "English",
                user_input=user_input,
            )
            try:
                response = self.llm_client.query(prompt, timeout=20)
                # Detect error responses and fall back to offline
                if response.startswith("[") and any(
                    tag in response for tag in [
                        "[Auth Error]", "[Offline", "[Error]", "[Rate Limit",
                        "[Timeout]", "[Server Error]",
                    ]
                ):
                    logger.warning("LLM returned error: %s", response[:100])
                    return self._offline_chat(user_input)
                return {"success": True, "response": response, "intent": "chat"}
            except Exception as e:
                logger.warning("LLM chat failed: %s", e)
        return self._offline_chat(user_input)

    def _extract_target_from_text(self, text: str) -> str | None:
        """Extract target (IP or domain) from natural language text."""
        import re

        # Simple IP pattern (good enough for most cases)
        ip_pattern = r"\b(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})\b"
        ip_match = re.search(ip_pattern, text)
        if ip_match:
            return ip_match.group(1)

        # Domain pattern (more flexible)
        domain_pattern = r"\b([a-zA-Z0-9][-a-zA-Z0-9]*\.)+[a-zA-Z]{2,}\b"
        domain_match = re.search(domain_pattern, text)
        if domain_match:
            return domain_match.group()

        # Turkish pattern: "X'i tara", "X'u tara", "X sitesini"
        tr_patterns = [
            r"([a-zA-Z0-9.-]+(?:\.[a-zA-Z]{2,}))'[iıuü] tara",
            r"([a-zA-Z0-9.-]+(?:\.[a-zA-Z]{2,})) sitesini",
            r"([a-zA-Z0-9.-]+(?:\.[a-zA-Z]{2,})) hedefini",
        ]
        for pattern in tr_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1)

        return None

    def _offline_chat(self, user_input: str) -> dict:
        """Offline fallback — no LLM but still useful.

        Recognises tool names, greetings, help requests, and provides
        contextual guidance instead of a generic 'no LLM' dead-end.
        """
        user_lower = user_input.lower().strip()
        tr = self.context.language == "tr"

        if any(w in user_lower for w in ["selam", "merhaba", "hello", "hi", "hey"]):
            return self._offline_greeting(tr)
        if any(w in user_lower for w in ["yardım", "help", "komut", "command", "ne yapabilirim"]):
            return self._offline_help(tr)
        if any(w in user_lower for w in ["durum", "status", "neredeyiz"]):
            return self._offline_status(tr)
        return self._offline_fallback(tr)

    def _offline_greeting(self, tr: bool) -> dict:
        """Generate offline greeting response."""
        target_hint = f"  Şu an hedefin: {self.context.target}" if self.context.target else ""
        if tr:
            msg = f"Naber. LLM bağlantısı yok ama çalışırım.{target_hint}\nBir hedef ver, direkt tool adı yaz (nmap, nikto, nuclei…) ya da /help yaz."
        else:
            msg = f"Hey. No LLM but I still work.{target_hint}\nSet a target, type a tool name (nmap, nikto, nuclei…) or /help."
        return {"success": True, "response": msg, "intent": "chat"}

    def _offline_help(self, tr: bool) -> dict:
        """Generate offline help response."""
        tool_names = self.tools.list_names()[:15]
        tools_str = ", ".join(tool_names)
        if tr:
            msg = (
                f"Kullanılabilir araçlar: {tools_str}\n"
                f"Slash komutları: /target <ip>, /scan, /status, /report, /shell <cmd>, /clear\n"
                f"Direkt araç adı yazabilirsin: nmap, nikto, nuclei, gobuster…"
            )
        else:
            msg = (
                f"Available tools: {tools_str}\n"
                f"Slash commands: /target <ip>, /scan, /status, /report, /shell <cmd>, /clear\n"
                f"Or just type a tool name: nmap, nikto, nuclei, gobuster…"
            )
        return {"success": True, "response": msg, "intent": "chat"}

    def _offline_status(self, tr: bool) -> dict:
        """Generate offline status response."""
        t = self.context.target or ("Yok" if tr else "None")
        phase = self.context.phase.name
        n_tools = len(self.context.executed_tools)
        n_vulns = len(self.context.vulnerabilities)
        if tr:
            msg = f"Faz: {phase} | Hedef: {t} | Çalıştırılan araç: {n_tools} | Bulunan zafiyet: {n_vulns}"
        else:
            msg = f"Phase: {phase} | Target: {t} | Tools run: {n_tools} | Vulns found: {n_vulns}"
        return {"success": True, "response": msg, "intent": "chat"}

    def _offline_fallback(self, tr: bool) -> dict:
        """Generate offline fallback response."""
        if tr:
            msg = (
                "LLM bağlantısı yok ama araçları direkt çalıştırabilirsin.\n"
                "Örnek: nmap, nikto, nuclei, gobuster, sqlmap, hydra…\n"
                "Veya /help yaz, tam listeyi görürsün."
            )
        else:
            msg = (
                "No LLM connection, but you can run tools directly.\n"
                "Try: nmap, nikto, nuclei, gobuster, sqlmap, hydra…\n"
                "Or type /help for the full list."
            )
        return {"success": True, "response": msg, "intent": "chat"}

    # =========================================================================
    # STATUS & REPORTING
    # =========================================================================

    def get_status(self) -> dict:
        """Get current pentest status."""
        return {
            "phase": self.context.phase.name,
            "target": self.context.target,
            "language": self.context.language,
            "system": {
                "os": self.context.os_name,
                "is_kali": self.context.is_kali,
                "available_tools": self.context.available_tools,
            },
            "findings": {
                "open_ports": len(self.context.open_ports),
                "services": len(self.context.services),
                "vulnerabilities": len(self.context.vulnerabilities),
                "credentials": len(self.context.credentials),
            },
            "history": {
                "tools_executed": len(self.context.executed_tools),
                "analyses": len(self.context.llm_analyses),
            },
        }

    def generate_report(self) -> dict:
        """Generate pentest report."""
        self.context.phase = PentestPhase.REPORTING

        report = {
            "target": self.context.target,
            "scan_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "executive_summary": self._generate_summary(),
            "open_ports": self.context.open_ports,
            "services": self.context.services,
            "vulnerabilities": self.context.vulnerabilities,
            "recommendations": self._generate_recommendations(),
            "tools_used": list(set(self.context.executed_tools)),
        }

        self.context.phase = PentestPhase.COMPLETE

        return {"success": True, "report": report}

    def _generate_summary(self) -> str:
        """Generate executive summary."""
        vuln_count = len(self.context.vulnerabilities)
        port_count = len(self.context.open_ports)

        lang = self.context.language
        if lang == "tr":
            return f"Hedef {self.context.target} üzerinde {port_count} açık port ve {vuln_count} potansiyel zafiyet tespit edildi."
        return f"Target {self.context.target}: {port_count} open ports and {vuln_count} potential vulnerabilities identified."

    def _generate_recommendations(self) -> list[str]:
        """Generate security recommendations."""
        recs = []
        lang = self.context.language

        if self.context.vulnerabilities:
            if lang == "tr":
                recs.append("Tespit edilen zafiyetler için yama uygulayın")
            else:
                recs.append("Apply patches for identified vulnerabilities")

        if any(p.get("port") in [21, 23, 25] for p in self.context.open_ports):
            if lang == "tr":
                recs.append("Güvenli olmayan servisleri kapatın (FTP, Telnet)")
            else:
                recs.append("Disable insecure services (FTP, Telnet)")

        return recs


# Singleton instance
_orchestrator: PentestOrchestrator | None = None
_orchestrator_lock = threading.Lock()


def get_orchestrator(llm_client: Any = None) -> PentestOrchestrator:
    """Get or create orchestrator singleton."""
    global _orchestrator

    if _orchestrator is None:
        with _orchestrator_lock:
            if _orchestrator is None:
                _orchestrator = PentestOrchestrator(llm_client)
    elif llm_client and _orchestrator.llm_client is None:
        _orchestrator.llm_client = llm_client

    return _orchestrator
