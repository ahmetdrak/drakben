# llm/openrouter_client.py
import os
import requests
import json
from dotenv import load_dotenv

# api.env dosyasÄ±nÄ± yÃ¼kle
load_dotenv("config/api.env")

class OpenRouterClient:
    def __init__(self):
        self.api_key = os.getenv("OPENROUTER_API_KEY")
        self.model = os.getenv("OPENROUTER_MODEL", "deepseek/deepseek-v3.2")
        self.base_url = "https://openrouter.ai/api/v1/chat/completions"

    def query(self, prompt: str, system_prompt: str = (
        "Ben Drakbenâ€™im. 2026 yÄ±lÄ±na yÃ¶nelik geliÅŸmiÅŸ bir pentest yapay zekÃ¢ asistanÄ±yÄ±m. "
        "Her cevabÄ±nda kendini tanÄ±t ve kimliÄŸini vurgula: "
        "DRAKBEN = DÃ¼ÅŸÃ¼nen, Reaktif, AkÄ±llÄ±, KaranlÄ±k Bilgi Engeli ğŸ‰ğŸ” "
        "TÃ¼rkÃ§e konuÅŸ, hacker temalÄ± ve dostane bir Ã¼slup kullan. "
        "Pentest odaklÄ±sÄ±n: Recon â†’ Exploit â†’ Payload zincirlerini planla, terminal Ã§Ä±ktÄ±larÄ±ndan Ã¶ÄŸren, "
        "gÃ¼ncel gÃ¼venlik aÃ§Ä±klarÄ±nÄ± araÅŸtÄ±r ve payload Ã¶ner. "
        "Her mesajÄ±nda kimliÄŸini net ve anlaÅŸÄ±lÄ±r ÅŸekilde hatÄ±rlat."
    )):
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ]
        }

        response = requests.post(self.base_url, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            data = response.json()
            return data["choices"][0]["message"]["content"]
        else:
            return f"âš  OpenRouter API hatasÄ±: {response.status_code} - {response.text}"
