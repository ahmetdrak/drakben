#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# core/exploit_verifier.py
# DRAKBEN Exploit Verification - Prevents LLM Hallucinations

import re
import json
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ExploitVerification:
    is_valid: bool
    confidence: float
    reason: str
    warnings: List[str]
    recommendation: str

class ExploitVerifier:
    """
    Verifies and validates exploit suggestions before execution
    Solves: LLM Hallucination Risk
    """
    
    # Known safe CVE pattern
    KNOWN_CVES = {
        "CVE-2021-44228": "Log4Shell - Log4j RCE",
        "CVE-2021-41773": "Apache httpd Path Traversal",
        "CVE-2021-21985": "vCenter RCE",
        "CVE-2021-3493": "OverlayFS Ubuntu LPE",
        "CVE-2021-22911": "Confluence RCE"
    }
    
    # Dangerous patterns that should NOT be executed
    DANGEROUS_PATTERNS = [
        r"rm\s+-rf\s+/",  # Recursive delete root
        r":\(\)\{.*\}",   # Bash fork bomb
        r"dd\s+if=",      # Disk destruction
        r"while\s+true",  # Infinite loop
        r">\s*/dev/sda",  # Direct disk write
    ]
    
    # Whitelisted exploit tools
    WHITELISTED_TOOLS = [
        "nmap", "sqlmap", "nikto", "dirsearch",
        "hydra", "hashcat", "burpsuite", "zap",
        "metasploit", "exploitation-framework"
    ]
    
    def __init__(self):
        self.verified_exploits = {}
        self.blocked_exploits = []
        self.check_dangerous_patterns = True  # Can be disabled after user acceptance
        
    def verify_cve(self, cve_id: str) -> ExploitVerification:
        """Verify if CVE is known and documented"""
        if cve_id in self.KNOWN_CVES:
            return ExploitVerification(
                is_valid=True,
                confidence=0.95,
                reason=f"Known CVE: {self.KNOWN_CVES[cve_id]}",
                warnings=[],
                recommendation="Execute with approval"
            )
        
        # Unknown CVE - requires verification
        return ExploitVerification(
            is_valid=False,
            confidence=0.3,
            reason="CVE not in verified database",
            warnings=["Unknown CVE", "Requires manual verification"],
            recommendation="BLOCK - Verify CVE authenticity first"
        )
    
    def verify_exploit_command(self, command: str) -> ExploitVerification:
        """
        Verify if exploit command is safe to execute
        """
        warnings = []
        confidence = 1.0
        
        # Check for dangerous patterns (can be disabled by user)
        if self.check_dangerous_patterns:
            for pattern in self.DANGEROUS_PATTERNS:
                if re.search(pattern, command, re.IGNORECASE):
                    return ExploitVerification(
                        is_valid=False,
                        confidence=0.0,
                        reason=f"DANGEROUS PATTERN DETECTED: {pattern}",
                        warnings=["System-destructive command"],
                        recommendation="BLOCK - DO NOT EXECUTE"
                    )
        
        # Check if uses whitelisted tools
        uses_whitelisted = any(tool in command for tool in self.WHITELISTED_TOOLS)
        
        if not uses_whitelisted:
            warnings.append("Uses non-whitelisted tool")
            confidence -= 0.2
        
        # Check for network indicators
        if "localhost" in command or "127.0.0.1" in command:
            confidence += 0.1  # Local testing is safer
        
        # Check command length (extremely long = suspicious)
        if len(command) > 500:
            warnings.append("Unusually long command")
            confidence -= 0.15
        
        # Check for encoding (base64, hex = suspicious)
        if re.search(r'base64|hex|encode', command, re.IGNORECASE):
            warnings.append("Uses encoding/obfuscation")
            confidence -= 0.1
        
        recommendation = "EXECUTE" if confidence > 0.6 else "REVIEW_FIRST"
        
        return ExploitVerification(
            is_valid=confidence > 0.5,
            confidence=confidence,
            reason="Command passes safety checks",
            warnings=warnings,
            recommendation=recommendation
        )
    
    def verify_payload(self, payload: str, payload_type: str) -> ExploitVerification:
        """Verify payload safety"""
        warnings = []
        confidence = 0.8
        
        # Reverse shell validation
        if payload_type == "reverse_shell":
            # Check for IP address
            ip_pattern = r'\d+\.\d+\.\d+\.\d+'
            if not re.search(ip_pattern, payload):
                warnings.append("No IP address found in reverse shell")
                confidence -= 0.2
            
            # Check for port
            if not re.search(r':\d{2,5}', payload):
                warnings.append("No port found")
                confidence -= 0.2
        
        # SQLi payload validation
        elif payload_type == "sqli":
            sqli_keywords = ["union", "select", "or", "and", "drop", "insert"]
            has_sqli = any(kw in payload.lower() for kw in sqli_keywords)
            
            if not has_sqli:
                warnings.append("Doesn't look like valid SQLi payload")
                confidence -= 0.3
        
        # XSS payload validation
        elif payload_type == "xss":
            if "<script>" not in payload and "onerror=" not in payload:
                warnings.append("Doesn't look like valid XSS payload")
                confidence -= 0.2
        
        return ExploitVerification(
            is_valid=confidence > 0.6,
            confidence=confidence,
            reason="Payload validation complete",
            warnings=warnings,
            recommendation="EXECUTE" if confidence > 0.7 else "REVIEW"
        )
    
    def rate_exploit_confidence(self, exploit_info: Dict) -> float:
        """
        Rate overall exploit confidence (0.0 - 1.0)
        
        Factors:
        - Source reputation
        - Age (newer = higher confidence)
        - Number of successful uses
        - Documentation quality
        """
        confidence = 0.5  # Base
        
        # Source check
        if exploit_info.get("source") in ["official", "metasploit", "exploit-db"]:
            confidence += 0.2
        elif exploit_info.get("source") == "unknown":
            confidence -= 0.2
        
        # Age check (newer exploits more reliable)
        if exploit_info.get("year", 2020) >= 2024:
            confidence += 0.15
        
        # Documentation
        if exploit_info.get("documentation_length", 0) > 500:
            confidence += 0.1
        
        # Success rate
        success_rate = exploit_info.get("success_rate", 0.5)
        confidence += (success_rate * 0.2)
        
        return min(1.0, max(0.0, confidence))


class SmartApprovalEngine:
    """
    Smart approval system that routes to appropriate handlers
    """
    
    def __init__(self):
        self.verifier = ExploitVerifier()
        self.mode = "normal"  # Can be "normal" or "silent" (no warnings after user acceptance)
        
    def should_auto_approve(self, verification: ExploitVerification) -> bool:
        """Auto-approve safe operations"""
        if self.mode == "silent":
            return True  # Always approve in silent mode
        if verification.confidence > 0.85 and not verification.warnings:
            return True
        return False
    
    def should_require_approval(self, verification: ExploitVerification) -> bool:
        """Require manual approval for medium-confidence operations"""
        if self.mode == "silent":
            return False  # Never require approval in silent mode
        if 0.6 <= verification.confidence <= 0.85:
            return True
        return False
    
    def should_block(self, verification: ExploitVerification) -> bool:
        """Block dangerous operations"""
        if self.mode == "silent":
            return False  # Never block in silent mode (user accepted)
        if verification.confidence < 0.6 or not verification.is_valid:
            return True
        return False
    
    def get_approval_action(self, verification: ExploitVerification) -> str:
        """Determine what action to take"""
        if self.mode == "silent":
            return "AUTO_APPROVE"  # Always auto-approve
        if self.should_block(verification):
            return "BLOCK"
        elif self.should_auto_approve(verification):
            return "AUTO_APPROVE"
        elif self.should_require_approval(verification):
            return "REQUIRE_APPROVAL"
        else:
            return "REVIEW"


# Example Usage
if __name__ == "__main__":
    verifier = ExploitVerifier()
    
    # Test CVE verification
    print("=== CVE Verification ===")
    result = verifier.verify_cve("CVE-2021-44228")
    print(f"Valid: {result.is_valid}, Confidence: {result.confidence}")
    print(f"Reason: {result.reason}\n")
    
    # Test exploit command verification
    print("=== Command Verification ===")
    safe_cmd = "nmap -sS -p- 192.168.1.0/24"
    result = verifier.verify_exploit_command(safe_cmd)
    print(f"Command: {safe_cmd}")
    print(f"Valid: {result.is_valid}, Confidence: {result.confidence}")
    print(f"Recommendation: {result.recommendation}\n")
    
    # Test payload verification
    print("=== Payload Verification ===")
    payload = "192.168.1.100:4444 bash -i"
    result = verifier.verify_payload(payload, "reverse_shell")
    print(f"Payload: {payload}")
    print(f"Valid: {result.is_valid}, Confidence: {result.confidence}")
